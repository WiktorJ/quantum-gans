{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For colab\n",
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow==2.3.1 tensorflow-quantum\n",
    "!rm -rf quantum-gans\n",
    "!git clone https://github.com/WiktorJ/quantum-gans\n",
    "!cd quantum-gans; pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import numpy as np\n",
    "from qsgenerator.utils import map_to_radians\n",
    "from qsgenerator.qugans import circuits\n",
    "from qsgenerator.qugans.training import Trainer\n",
    "from qsgenerator.phase.circuits import build_ground_state_circuit\n",
    "from qsgenerator.phase.analitical import  get_ground_state_for_g\n",
    "from qsgenerator.states.simple_state_circuits import build_x_rotation_state\n",
    "from qsgenerator.states.simple_rotation_generators import get_binary_x_rotation_provider \n",
    "from qsgenerator.phase.analitical import construct_hamiltonian, get_theta_v, get_theta_w, get_theta_r, get_g_parameters_provider\n",
    "from qsgenerator.evaluators.circuit_evaluator import CircuitEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_layers = 3\n",
    "discriminator_layers = 5\n",
    "data_bus_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen, gs, disc, ds, ls, data_qubits, out_qubit = circuits.build_gan_circuits(generator_layers, discriminator_layers, data_bus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real, real_symbols = build_ground_state_circuit(qubits=data_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real, real_symbols = build_x_rotation_state(qubits=data_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_gen = gen.copy()\n",
    "gen.append([disc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_real = real.copy()\n",
    "real.append([disc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL GROUND STATE\n",
      "(0, 2): ───Rx(r0)───\n",
      "\n",
      "(0, 3): ───Rx(r1)───\n",
      "\n",
      "(0, 4): ───Rx(r2)───\n"
     ]
    }
   ],
   "source": [
    "print(\"REAL GROUND STATE\")\n",
    "print(pure_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATOR\n",
      "(0, 2): ───Rx(l)───Rx(g0)───Rz(g4)───ZZ───────────────Rx(g11)───Rz(g15)───ZZ────────────────Rx(g22)───Rz(g26)───ZZ────────────────\n",
      "                                     │                                    │                                     │\n",
      "(0, 3): ───Rx(l)───Rx(g1)───Rz(g5)───ZZ^g8───ZZ───────Rx(g12)───Rz(g16)───ZZ^g19───ZZ───────Rx(g23)───Rz(g27)───ZZ^g30───ZZ───────\n",
      "                                             │                                     │                                     │\n",
      "(0, 4): ───Rx(l)───Rx(g2)───Rz(g6)───ZZ──────ZZ^g10───Rx(g13)───Rz(g17)───ZZ───────ZZ^g21───Rx(g24)───Rz(g28)───ZZ───────ZZ^g32───\n",
      "                                     │                                    │                                     │\n",
      "(0, 5): ───Rx(l)───Rx(g3)───Rz(g7)───ZZ^g9────────────Rx(g14)───Rz(g18)───ZZ^g20────────────Rx(g25)───Rz(g29)───ZZ^g31────────────\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATOR\")\n",
    "print(pure_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISCRIMINATOR\n",
      "(0, 0): ───Rx(l)───Rx(d0)───Rz(d5)───ZZ────────────────Rx(d14)───Rz(d19)───ZZ────────────────Rx(d28)───Rz(d33)───ZZ────────────────Rx(d42)───Rz(d47)───ZZ────────────────Rx(d56)───Rz(d61)───ZZ────────────────\n",
      "                                     │                                     │                                     │                                     │                                     │\n",
      "(0, 1): ───Rx(l)───Rx(d1)───Rz(d6)───ZZ^d10───ZZ───────Rx(d15)───Rz(d20)───ZZ^d24───ZZ───────Rx(d29)───Rz(d34)───ZZ^d38───ZZ───────Rx(d43)───Rz(d48)───ZZ^d52───ZZ───────Rx(d57)───Rz(d62)───ZZ^d66───ZZ───────\n",
      "                                              │                                     │                                     │                                     │                                     │\n",
      "(0, 2): ───Rx(l)───Rx(d2)───Rz(d7)───ZZ───────ZZ^d12───Rx(d16)───Rz(d21)───ZZ───────ZZ^d26───Rx(d30)───Rz(d35)───ZZ───────ZZ^d40───Rx(d44)───Rz(d49)───ZZ───────ZZ^d54───Rx(d58)───Rz(d63)───ZZ───────ZZ^d68───\n",
      "                                     │                                     │                                     │                                     │                                     │\n",
      "(0, 3): ───Rx(l)───Rx(d3)───Rz(d8)───ZZ^d11───ZZ───────Rx(d17)───Rz(d22)───ZZ^d25───ZZ───────Rx(d31)───Rz(d36)───ZZ^d39───ZZ───────Rx(d45)───Rz(d50)───ZZ^d53───ZZ───────Rx(d59)───Rz(d64)───ZZ^d67───ZZ───────\n",
      "                                              │                                     │                                     │                                     │                                     │\n",
      "(0, 4): ───Rx(l)───Rx(d4)───Rz(d9)────────────ZZ^d13───Rx(d18)───Rz(d23)────────────ZZ^d27───Rx(d32)───Rz(d37)────────────ZZ^d41───Rx(d46)───Rz(d51)────────────ZZ^d55───Rx(d60)───Rz(d65)────────────ZZ^d69───\n"
     ]
    }
   ],
   "source": [
    "print(\"DISCRIMINATOR\")\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "eps = 1e-2\n",
    "init_gen_weights = np.array([0] * len(gs)) + \\\n",
    "                   np.random.normal(scale=eps, size=(len(gs),))\n",
    "init_disc_weights = np.random.normal(size=(len(ds),))\n",
    "\n",
    "gen_weights = tf.Variable(init_gen_weights, dtype=tf.float32)\n",
    "disc_weights = tf.Variable(init_disc_weights, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, warmup_steps=4000):\n",
    "        super(CustomScheduler, self).__init__()\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        return max(math.e ** - ((step+200) / (self.warmup_steps / math.log(100))), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomScheduler()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g_provider = lambda: random.choice([0, 1, 2])\n",
    "x_rotations = get_binary_x_rotation_provider({0: '100', 1: '011', 2: '101'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(g_provider, \n",
    "                  data_bus_size, \n",
    "                  disc, \n",
    "                  gen, \n",
    "                  real, \n",
    "                  out_qubit, \n",
    "                  ds, \n",
    "                  gs, \n",
    "                  real_symbols, \n",
    "                  ls,\n",
    "                  real_values_provider = x_rotations,\n",
    "                  use_analytical_expectation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wiktorjurasz/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "----------------------------------------------------\n",
      "----------- AFTER DISCRIMINATOR TRAINING -----------\n",
      "Epoch 0: generator cost = [[-0.349853]]\n",
      "Epoch 0: discriminator cost = [[0.4387548]]\n",
      "Prob(fake classified as real):  [[0.349853]]\n",
      "Prob(real classified as real):  [[0.12418264]]\n",
      "----------- AFTER GENERATOR TRAINING -----------\n",
      "Epoch 0: generator cost = [[-0.78478575]]\n",
      "Epoch 0: discriminator cost = [[0.4413286]]\n",
      "Prob(fake classified as real):  [[0.34716052]]\n",
      "Prob(real classified as real):  [[0.7595391]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b0b5bff4624a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgen_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_interval_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m trainer.train(disc_weights,\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mgen_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/qsgenerator/qugans/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, disc_weights, gen_weights, opt, disc_cost, gen_cost, epochs, disc_iteration, gen_iteration, print_interval_epoch, print_weights)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mcost_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[0;32m--> 374\u001b[0;31m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    375\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1065\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36mactual_grad_fn\u001b[0;34m(*result_grads)\u001b[0m\n\u001b[1;32m    444\u001b[0m                          \"@custom_gradient grad_fn.\")\n\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0minput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m       \u001b[0mvariable_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mflat_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 return self._differentiate_ana(programs, symbol_names,\n\u001b[0m\u001b[1;32m    132\u001b[0m                                                \u001b[0msymbol_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpauli_sums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                                forward_pass_vals, grad)\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36m_differentiate_ana\u001b[0;34m(self, programs, symbol_names, symbol_values, pauli_sums, forward_pass_vals, grad)\u001b[0m\n\u001b[1;32m    160\u001b[0m     def _differentiate_ana(self, programs, symbol_names, symbol_values,\n\u001b[1;32m    161\u001b[0m                            pauli_sums, forward_pass_vals, grad):\n\u001b[0;32m--> 162\u001b[0;31m         return None, None, self.differentiate_analytic(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mprograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             pauli_sums, forward_pass_vals, grad), \\\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Studies/thesis/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 101\n",
    "disc_iteration = 100\n",
    "gen_iteration = 10\n",
    "print_interval_epoch = 10\n",
    "trainer.train(disc_weights,\n",
    "      gen_weights, \n",
    "      opt, \n",
    "      epochs=epochs, \n",
    "      disc_iteration=disc_iteration, \n",
    "      gen_iteration=gen_iteration,\n",
    "      print_interval_epoch=print_interval_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_for_g(g, gen_weights):\n",
    "    rad = map_to_radians(g)\n",
    "    return np.append(gen_weights, rad)\n",
    "\n",
    "def get_variables_real(g):\n",
    "    return np.array([get_theta_v(g), get_theta_w(g), get_theta_r(g)])\n",
    "\n",
    "def get_states_and_fidelty_for_real(gen_evaluator, real_evaluator, gen_weights, g, size):\n",
    "    generated = gen_evaluator.get_state_from_params(get_gen_for_g(g, gen_weights), list(range(size)))\n",
    "    real = real_evaluator.get_state_from_params(get_variables_real(g))\n",
    "    return generated, real, cirq.fidelity(generated, real)\n",
    "\n",
    "def get_states_and_fidelty_for_ground(gen_evaluator, g, gen_weights, size):\n",
    "    generated = gen_evaluator.get_state_from_params(get_gen_for_g(g, gen_weights), list(range(size)))\n",
    "    ground = get_ground_state_for_g(g, size)\n",
    "    return generated, ground, cirq.fidelity(generated, ground)\n",
    "\n",
    "def compare_generated_for_g(gen_evaluator, g1, g2, gen_weights, size):\n",
    "     generated1 = gen_evaluator.get_state_from_params(get_gen_for_g(g1, gen_weights), list(range(size)))\n",
    "     generated2 = gen_evaluator.get_state_from_params(get_gen_for_g(g2, gen_weights), list(range(size)))\n",
    "     return generated1, generated2, cirq.fidelity(generated1, generated2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trained_disc_weights = tf.Variable(np.array([ 1.25888796e+01,  1.10409822e+01,  1.27487049e+01,  1.32927475e+01,\n",
    "       -3.20522385e+01,  2.98508596e+00, -7.54223883e-01,  8.97036648e+00,\n",
    "        8.98472309e+00, -2.77423954e+00,  8.90891266e+00,  5.72837019e+00,\n",
    "        6.03105211e+00, -4.64482594e+00, -1.10843427e-01,  7.78598115e-02,\n",
    "        3.00343895e+00,  3.83781940e-01,  6.08641243e+00,  8.64131927e+00,\n",
    "       -2.17593918e+01,  1.45857897e+01,  2.36893883e+01,  8.75363445e+00,\n",
    "       -2.42768993e+01,  1.27688437e+01,  2.53628349e+00,  1.39768391e+01,\n",
    "        1.40961084e+01, -2.04474068e+01,  4.71392822e+00,  1.66926212e+01,\n",
    "        1.88311214e+01,  9.17525005e+00,  1.16109962e+01,  1.08004580e+01,\n",
    "        1.10795708e+01,  5.81477690e+00, -5.50215101e+00,  2.22007637e+01,\n",
    "        2.25015125e+01,  3.21826210e+01, -1.80058708e+01, -7.85126591e+00,\n",
    "       -7.77073908e+00,  1.40237570e+01,  3.14071465e+01, -1.07477732e+01,\n",
    "        1.55852342e+00,  2.63786411e+01,  1.31890945e+01,  7.14759350e+00,\n",
    "        5.46145630e+00, -1.79730053e+01,  7.40563774e+00,  1.06135674e+01,\n",
    "       -1.55095673e+00, -2.66580944e+01,  6.51995277e+00, -2.37151980e+00,\n",
    "        3.51896515e+01,  1.50027342e+01,  1.80733763e-02, -1.75052185e+01,\n",
    "        9.60706902e+00, -6.06413984e+00,  5.35433817e+00, -7.88707399e+00,\n",
    "        1.27363043e+01,  1.02446747e+01]), dtype=tf.float32)\n",
    "\n",
    "trained_gen_weights = np.array([  0.83756703,  -8.85081   ,   5.5571547 ,   6.2937136 ,\n",
    "       -11.173263  ,  -5.2586904 ,  15.195034  ,  -2.752592  ,\n",
    "        -2.758591  , -11.47981   ,  -5.061309  ,   3.2534666 ,\n",
    "        -5.6829824 , -22.536098  ,   9.015973  ,   0.5836532 ,\n",
    "         2.1221178 ,   5.4982877 ,  13.235283  ,   3.4571006 ,\n",
    "        -0.6003567 ,  -5.9493637 ,  -8.738516  ,   0.4041    ,\n",
    "         6.9204884 ,  -6.442905  ,  -9.274843  ,  -3.695387  ,\n",
    "        10.760881  ,   2.24611   ,   0.5289249 ,  14.787433  ,\n",
    "       -11.227607])\n",
    "\n",
    "gen_symbols = gs + (ls,)\n",
    "real_symbols = ('r0', 'r1', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_evaluator = CircuitEvaluator(pure_gen, gen_symbols)\n",
    "real_evaluator = CircuitEvaluator(pure_real, real_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max probability state after tracing has probability: 0.974941611289978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.08993246+0.j        ,  0.38960975-0.05731301j,\n",
       "         0.08879194+0.24945204j,  0.17451479-0.65830445j,\n",
       "         0.05236622-0.05087227j, -0.14689884+0.10184895j,\n",
       "        -0.07625695+0.15308213j,  0.43438524-0.21835442j], dtype=complex64),\n",
       " array([ 0.11732721+0.j        ,  0.        -0.03710212j,\n",
       "         0.        -0.76015157j, -0.24038103+0.j        ,\n",
       "         0.        -0.08595169j, -0.02718031+0.j        ,\n",
       "        -0.55687267+0.j        ,  0.        +0.1760986j ], dtype=complex64),\n",
       " 0.05823949895534164)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = -10\n",
    "get_states_and_fidelty_for_real(gen_evaluator, real_evaluator, trained_gen_weights, g, data_bus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max probability state after tracing has probability: 0.974941611289978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.08993246+0.j        ,  0.38960975-0.05731301j,\n",
       "         0.08879194+0.24945204j,  0.17451479-0.65830445j,\n",
       "         0.05236622-0.05087227j, -0.14689884+0.10184895j,\n",
       "        -0.07625695+0.15308213j,  0.43438524-0.21835442j], dtype=complex64),\n",
       " array([ 0.76015157+0.j        ,  0.        -0.24038103j,\n",
       "         0.        -0.11732721j, -0.03710212+0.j        ,\n",
       "         0.        -0.55687267j, -0.1760986 +0.j        ,\n",
       "        -0.08595169+0.j        ,  0.        +0.02718031j], dtype=complex64),\n",
       " 0.014430476418150429)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = 10\n",
    "get_states_and_fidelty_for_real(gen_evaluator, real_evaluator, trained_gen_weights, g, data_bus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max probability state after tracing has probability: 0.9781550168991089\n",
      "Max probability state after tracing has probability: 0.981857419013977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.0841965 +0.j        ,  0.18691188+0.1448713j ,\n",
       "        -0.04824434-0.12588938j, -0.69796413+0.39543998j,\n",
       "         0.09763314+0.01778871j, -0.23618338-0.27832115j,\n",
       "         0.03212571-0.0409976j , -0.33659515-0.12720747j], dtype=complex64),\n",
       " array([-0.0923465 +0.0000000e+00j, -0.07581477-4.6684846e-01j,\n",
       "         0.08082028-1.9660823e-01j,  0.20732668+6.3416529e-01j,\n",
       "         0.01657245+1.6675850e-02j, -0.07306691+1.8806756e-01j,\n",
       "         0.14650305-2.5829076e-04j, -0.3853701 +2.5730491e-01j],\n",
       "       dtype=complex64),\n",
       " 0.6142508851638837)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_generated_for_g(gen_evaluator, -9, 9, trained_gen_weights, data_bus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max probability state after tracing has probability: 0.981857419013977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.0923465 +0.0000000e+00j, -0.07581477-4.6684846e-01j,\n",
       "         0.08082028-1.9660823e-01j,  0.20732668+6.3416529e-01j,\n",
       "         0.01657245+1.6675850e-02j, -0.07306691+1.8806756e-01j,\n",
       "         0.14650305-2.5829076e-04j, -0.3853701 +2.5730491e-01j],\n",
       "       dtype=complex64),\n",
       " array([0.35355339, 0.35355339, 0.35355339, 0.35355339, 0.35355339,\n",
       "        0.35355339, 0.35355339, 0.35355339]),\n",
       " 0.027226466798719495)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = 1\n",
    "get_states_and_fidelty_for_ground(gen_evaluator, g, gen_weights, data_bus_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
