\chapter{Generative Adversarial Networks Introduction}\label{chapter:gans}
Generative Adversarial Network (GAN)\cite{goodfellow2014generative} is a
machine learning framework designed to estimate generative models using
adversarial process. At the core it consists of two models: the generative one
$G$ which is capable of learning the distribution of the provided data and
discriminative model $D$ that, given a data point, estimates whether it comes
from input data or was generated by $G$. The models are set to compete with each
other in a minmax game. $D$ is trained to maximize the probability of correctly
distinguishing between the generated and real samples, while $G$ is trained to
minimize it.  

To approximate the true distribution $p_r$ over data $X$ we define a prior noise
distribution $p_z$ over noise input $Z$ and the generator distribution $p_g$
over data $X$. The generator represents a mapping
$G(z \sim Z; \theta_g) \to x \sim X$, where $\theta_g$ is some learnable
parameter (summary in Table \ref{tab:gan_probabilities}).

The discriminator $D(x, \theta_d) -> [0;1]$ is a function that given a sample $x
\sim X$ outputs the probability whether $x$ comes from data or was generated by
$G$. 

In classical GANs both $G$ and $D$ are most often modeled as multi-layer
perceptrons\cite{goodfellow2014generative} or other types of neural networks
(e.g. convolutional neural networks \cite{radford2016unsupervised}). However,
there exist many different variations of cost functions used during the mixmax
training procedure. In the following paragraphs we take a closer look at two of
them, namely SGANs and WGANs, which are the most relevant in the context of this
work. To simply the notation, we skip the $\theta$ parameters, i.e. $G(z,
\theta_g) = G(z)$ and $D(x, \theta_d) = D(x)$
\begin{table}[]
  \centering
  \begin{tabular}{|l|l|}
    \hline
    Probability Distribution & Description  \\ \hline
    $p_z$ & True distribution over noise input $Z$ \\ \hline
    $p_g$&  Approximated distribution over input data $X$ given by $G$ \\ \hline
    $p_r$&  True distribution over input data $X$\\ \hline
  \end{tabular}
  \caption{\label{tab:gan_probabilities} Description of the probability
    distributions used in GANs}
\end{table}

\section{Standard Generative Adversarial Networks (SGANs)}
The goal of $D$ is to distinguish between the real and generated samples. For $x
\sim X$ the output $D(x)$ should approach $1$, while for $x \sim G(z)$ it should
approach $0$. In other terms it simultaneously maximizes $\mathbb{E}_{x \sim
  p_r(x)}[\log{D(x)}]$, and $\mathbb{E}_{z \sim p_z(z)}[\log{1 - D(G(z))}]$.

Generator $G$ has an opposite objective, thus it minimizes the $\mathbb{E}_{z
  \sim p_z(z)}[\log{1 - D(G(z))}]$.

Putting it all together, we get the loss function for SGANs.
\begin{equation}
  \begin{split}
  \min_G\max_D\mathcal{L(G, D)} & = \mathbb{E}_{x \sim p_r(x)}[\log{D(x)}] +  \mathbb{E}_{z \sim p_z(z)}[\log{1 - D(G(z))}] \\
  & = \mathbb{E}_{x \sim p_r(x)}[\log{D(x)}] +  \mathbb{E}_{x \sim p_g(x)}[\log{1 - D(x)}]
  \end{split}
\end{equation}
It can be shown, that if $D$ is optimal, this loss function measures the similarity between 
$p_r$ and $p_g$ according to Jensenâ€“Shannon divergence (see Appendix
\ref{apx:JSD} for detailed analysis). 

SGANs are a very powerful tool, however, the training process is very difficult
and unstable \cite{salimans2016improved}. Additionally, if the data exists in
low dimensional manifold (which seems to be the case for most real world data
\cite{narayanan2010proceedings}), we are always capable of finding the perfect discriminator 
\cite{arjovsky2017principled}. This might seem like a good
characteristic, but if we examine the loss function closer, we find that it
makes generator incapable of learning. For the perfect $D$ we have $\forall x
\sim X, D(x) = 1$ and $\forall z \sim Z, D(G(z)) = 0$, for those values
$\mathcal{L(G,D)} = 0$ gradient vanishes and the gradient based optimizers cannot improve the
generator anymore.
\section{Wasserstein Generative Adversarial Networks (WGANs)}
One of the very prominent improvement to SGANs and a way to mitigate the
vanishing gradient problem is changing the cost function to use Wasserstein
Distance.

The Wasserstein Distance, also called Earth-Mover's Distance is a distance
measure between two probability distributions. The name ``Earth Mover'' comes
from the fact, that informally the distance can be described as follows: Given
two probability distributions, if we imagine them as piles of dirt, the ``Earth
Mover'' distance says what is the minimum cost of turning one pile of dirt into the
other one. Where cost is the volume that has to be moved times the distance is
has to be moved.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: